{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1673b0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "0      Data Science         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6\n",
       "3     Data Engineer         4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6f8f9",
   "metadata": {},
   "source": [
    "#### Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242d216f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d5635",
   "metadata": {},
   "source": [
    "#### Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c195a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In pandas, the functions loc and iloc are used to access and manipulate data within a DataFrame, but they differ in the way they handle indexing.\n",
    "\n",
    "# loc: This function is primarily label-based, meaning it uses labels or names to access rows or columns in the DataFrame. It can accept boolean arrays as well. The syntax for using loc is df.loc[row_indexer, column_indexer].\n",
    "\n",
    "# iloc: This function is primarily integer-based, meaning it uses integer-based indexing to access rows or columns in the DataFrame. It does not accept boolean arrays. The syntax for using iloc is df.iloc[row_indexer, column_indexer].\n",
    "\n",
    "# To summarize the differences between the two:\n",
    "\n",
    "# loc uses labels or names for indexing, while iloc uses integer-based indexing.\n",
    "# loc can accept boolean arrays for filtering, while iloc cannot.\n",
    "# With loc, the end index is inclusive, while with iloc, the end index is exclusive.\n",
    "# Both loc and iloc can be used to access subsets of rows and columns in a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798fcc7",
   "metadata": {},
   "source": [
    "#### Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df then find the output for both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8e7cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Big Data\n",
       "duration              6\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindex = [3,0,1,2]\n",
    "new_df = df.reindex(reindex)\n",
    "new_df\n",
    "new_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d68751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed478f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reindexing, we can use new_df.loc[2] to access the row with label/index 2 and new_df.iloc[2] to access the row with integer index 2 in the new_df DataFrame.\n",
    "\n",
    "# Please note that since the indexing has changed after reindexing, the output of new_df.loc[2] will correspond to the row with label/index 2 in the new DataFrame, while new_df.iloc[2] will correspond to the row with integer index 2 in the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e3eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193221d",
   "metadata": {},
   "source": [
    "#### Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "#### (i) mean of each and every column present in the dataframe.\n",
    "#### (ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f5035d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.506407\n",
       "column_2    0.425934\n",
       "column_3    0.309808\n",
       "column_4    0.432101\n",
       "column_5    0.415326\n",
       "column_6    0.524650\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8d57bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2666721631075348"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column2_std = df1['column_2'].std()\n",
    "column2_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afacda72",
   "metadata": {},
   "source": [
    "#### Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "#### mean of column, column_2. If you are getting errors in executing it then explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50925e43",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_value\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Trying to calculate the mean of 'column_2'\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m column2_mean \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, column2_mean)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:11117\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11099\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11100\u001b[0m     _num_doc,\n\u001b[0;32m  11101\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11115\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11116\u001b[0m ):\n\u001b[1;32m> 11117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:10687\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  10680\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10681\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10685\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  10686\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 10687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  10688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  10689\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:10639\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10629\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  10630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  10631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10634\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  10635\u001b[0m     )\n\u001b[0;32m  10636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  10637\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  10638\u001b[0m     )\n\u001b[1;32m> 10639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  10641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4471\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   4468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4469\u001b[0m     )\n\u001b[0;32m   4470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:410\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 410\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    413\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:698\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    695\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    697\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 698\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    701\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the DataFrame 'df1' and want to replace the data in the second row of 'column_2' with a string\n",
    "new_value = 'replacement'\n",
    "\n",
    "# Incorrect code: Replacing data with a string\n",
    "df1.loc[1, 'column_2'] = new_value\n",
    "\n",
    "# Trying to calculate the mean of 'column_2'\n",
    "column2_mean = df1['column_2'].mean()\n",
    "print(\"Mean of column 'column_2':\", column2_mean)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06c4f236",
   "metadata": {},
   "source": [
    "# we will get an type error because two are different data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69de0b",
   "metadata": {},
   "source": [
    "#### Q6. What do you understand about the windows function in pandas and list the types of windowsfunctions?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f009ff90",
   "metadata": {},
   "source": [
    "In pandas, window functions are used for performing calculations over a specified window or a group of rows in a DataFrame or a Series. These functions provide a way to compute aggregated values based on a sliding or expanding window of data.\n",
    "\n",
    "Window functions are typically used in conjunction with the rolling() or expanding() methods in pandas. Here's a brief explanation of each:\n",
    "\n",
    "Rolling Window Functions:\n",
    "\n",
    "Rolling window functions apply a specified function or operation to a defined window of data that moves or rolls over the data. The window size can be fixed or variable.\n",
    "Examples of rolling window functions include mean(), sum(), min(), max(), std(), var(), cov(), corr(), etc.\n",
    "Expanding Window Functions:\n",
    "\n",
    "Expanding window functions compute the cumulative results over the entire range of the data, from the beginning up to the current position.\n",
    "Examples of expanding window functions include cumsum(), cumprod(), cummin(), cummax(), cumcount(), etc.\n",
    "Both rolling and expanding window functions can be applied using the rolling() and expanding() methods in pandas, respectively. These methods return a window or expanding object that allows you to apply various window functions to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d5767",
   "metadata": {},
   "source": [
    "#### Q7. Write a code to print only the current month and year at the time of answering this question.[Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf35d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month: 5\n",
      "Current Year: 2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = pd.to_datetime('today')\n",
    "\n",
    "# Extract the month and year from the current date and time\n",
    "current_month = current_datetime.month\n",
    "current_year = current_datetime.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"Current Month:\", current_month)\n",
    "print(\"Current Year:\", current_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47408fae",
   "metadata": {},
   "source": [
    "#### Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "#### calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "#### program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f237286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD): 2003-01-23\n",
      "Enter the second date (YYYY-MM-DD): 2023-01-23\n",
      "Time difference:\n",
      "Days: 7305\n",
      "Hours: 0\n",
      "Minutes: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the dates\n",
    "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Convert the input strings to pandas' datetime format\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "# Calculate the time difference\n",
    "time_diff = date2 - date1\n",
    "\n",
    "# Extract the days, hours, and minutes from the time difference\n",
    "days = time_diff.days\n",
    "hours = time_diff.seconds // 3600\n",
    "minutes = (time_diff.seconds % 3600) // 60\n",
    "\n",
    "# Display the result\n",
    "print(\"Time difference:\")\n",
    "print(\"Days:\", days)\n",
    "print(\"Hours:\", hours)\n",
    "print(\"Minutes:\", minutes)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "675e426e",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Prompt the user to enter the column name\n",
    "column_name = input(\"Enter the column name: \")\n",
    "\n",
    "# Prompt the user to enter the category order\n",
    "category_order = input(\"Enter the category order (comma-separated values): \").split(\",\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the specified column to categorical data type\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame based on the specified column\n",
    "sorted_df = df.sort_values(by=column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(\"Sorted Data:\")\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c5a4f",
   "metadata": {},
   "source": [
    "#### Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "#### visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "#### program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6e166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the CSV file path: placement_cla.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Product Category'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Group the data by product category and calculate the sum of sales for each category\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct Category\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get the unique product categories and sort them in descending order by sales\u001b[39;00m\n\u001b[0;32m     14\u001b[0m categories \u001b[38;5;241m=\u001b[39m grouped_df\u001b[38;5;241m.\u001b[39mindex\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7707\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7709\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7710\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7711\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7715\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7718\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Product Category'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group the data by product category and calculate the sum of sales for each category\n",
    "grouped_df = df.groupby('Product Category')['Sales'].sum()\n",
    "\n",
    "# Get the unique product categories and sort them in descending order by sales\n",
    "categories = grouped_df.index\n",
    "sorted_categories = sorted(categories, key=lambda x: grouped_df[x], reverse=True)\n",
    "\n",
    "# Create a stacked bar chart to visualize the sales of each product category over time\n",
    "plt.bar(df['Year'], df['Sales'], color='lightblue', label='Other Categories')\n",
    "bottom = df['Sales'].values.copy()\n",
    "\n",
    "for category in sorted_categories:\n",
    "    mask = df['Product Category'] == category\n",
    "    plt.bar(df['Year'], df['Sales'], bottom=bottom, label=category)\n",
    "    bottom += df.loc[mask, 'Sales'].values\n",
    "\n",
    "# Set the x-axis label and title\n",
    "plt.xlabel('Year')\n",
    "plt.title('Sales by Product Category over Time')\n",
    "\n",
    "# Rotate the x-axis tick labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display a legend and show the chart\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "The program should do the followingM\n",
    "I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "I Read the CSV file into a Pandas DataFrameR\n",
    "I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "I Student ID: The ID of the studentR\n",
    "I Test Score: The score of the student's test.\n",
    "Example usage of the program:\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the mean, median, and mode of the test scores\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_scores = df['Test Score'].mode()\n",
    "\n",
    "# Display the results in a table\n",
    "result_table = pd.DataFrame({\n",
    "    'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "    'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]\n",
    "})\n",
    "print(result_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
